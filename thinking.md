# Thinking1	在CTR点击率预估中，使用GBDT+LR的原理是什么？ #

答：
（1） 样本数量大，点击率预估模型中的训练样本可达上亿级别，大数据量会导致传统LR特征维度不充分，导致欠拟合。
（2）人工成本高，如果是传统LR，特征需要人工提取，首先对人工的经验要求高，其次时间成本会比较大


# Thinking2	Wide & Deep的模型结构是怎样的，为什么能通过具备记忆和泛化能力（memorization and generalization） #

答：	Wide & Deep模型由两部分组成
wide部分：主要负责特征的“记忆”部分，只要是记一维的items或者features之间的相关频率，如包括用户点击哪些商品，购买过哪些商品等，然后通过OneHot编码转换为离散特征。好处是可解释性强，不足在于如果需要特征组合，则需要人为操作。

feature部分：主要负责特征的“泛化”部分，其实也就是特征之间的组合信息。基于相关性的传递，去探索一些在过去没有出现过的特征组合。

Wide & Deep模型由这两个部分组合，并在最上层加了一个Logistic Loss，也就是sigmod作为转换，结合线性模型的记忆能力和DNN模型的泛化能力，在训练过程中同时优化两个模型的参数。两个模型分别对全量数据进行预测，然后根据权重组合最终的预测结果


# Thinking3	在CTR预估中，使用FM与DNN结合的方式，有哪些结合的方式，代表模型有哪些？ #

答： 串行和并行     串行的为NFM，并行的为Deepfm


# Thinking4	GBDT和随机森林都是基于树的算法，它们有什么区别？ #

答：
（1）随机森林基于Bagging思想，对数据集进行多次有放回抽样，每次的抽样进行分类计算生成弱分类器，对计算结果进行投票，看哪一种情况票数多即为最后结果。因为每次抽样为独立抽样，所以可以并行。

（2） GBDT是基于boosting思想，每一次选择的训练集都依赖于上一次学习的结果。GBDT是将所有树的结果累加起来，最为最终的结果 => 每一棵树学的是之前所有树结果和的残差，所以只能串行，不能并行。



# Thinking5	item流行度在推荐系统中有怎样的应用 #

答：
（1）内容的流行程度，也称之为热度，最常见的是将榜单中热度的内容推荐给用户（微博热搜，TopN商品）

（2）冷启动问题，当平台新开始，新用户还没有产生行为，无法使用协同过滤等算法，可以用流行度推荐来解决。














